import torch
import cv2
import numpy as np
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
import os

# æ£€æŸ¥ mmpretrain
try:
    from mmpretrain.apis import init_model
except ImportError:
    print("âŒ é”™è¯¯: è¯·å®‰è£… mmpretrain (pip install mmpretrain)")
    exit()

# ================= 1. é…ç½®åŒºåŸŸ =================

# 1.1 æ¨¡å‹è·¯å¾„
config_path = '/media/HDD0/wzl/mmcls/DLandCV-course/homework1/DL/mmclassification/configs/Amytest/D_10.py'
checkpoint_path = '/media/HDD0/wzl/mmcls/DLandCV-course/homework1/DL/mmclassification/work_dirs/D_10/best_accuracy_top1_epoch_29.pth'

# 1.2 å›¾ç‰‡è·¯å¾„
image_path = '/media/HDD0/wzl/mmcls/dataset_1/val/Potato leaf late blight/B2750109-Late_blight_on_a_potato_plant-SPL.jpg'

# 1.3 ç›®æ ‡å±‚ (ResNet-50)
target_layer_name = 'backbone.layer4[-1]'

# 1.4 ä¿å­˜è·¯å¾„
save_dir = "./error_ana"
save_name = "heatmap_original_size.png"

# =========================================================

class ModelWrapper(torch.nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model
    
    def forward(self, x):
        feats = self.model.extract_feat(x)
        if hasattr(self.model.head, 'forward'):
            try:
                logits = self.model.head(feats)
            except:
                if isinstance(feats, tuple): feat = feats[-1]
                else: feat = feats
                logits = self.model.head.fc(self.model.head.pre_logits(feat))
        else:
             logits = self.model.head.fc(feats)
        if isinstance(logits, dict):
            return logits['pred_scores']
        return logits

def get_target_layer(model, layer_str):
    try:
        parts = layer_str.replace('[-1]', '.__last__').split('.')
        current = model
        for part in parts:
            if part == '__last__': current = current[-1]
            elif '[' in part:
                name, idx = part[:-1].split('[')
                current = getattr(current, name)[int(idx)]
            else:
                current = getattr(current, part)
        return [current]
    except Exception as e:
        print(f"âŒ æ‰¾ä¸åˆ°å±‚ {layer_str}: {e}")
        return []

def main():
    # 1. åŠ è½½æ¨¡å‹
    print(f"ğŸš€ Loading model...")
    try:
        model = init_model(config_path, checkpoint_path, device='cuda:0')
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    # 2. è¯»å–åŸå›¾ (ä¿æŒåŸå§‹å°ºå¯¸)
    img_origin = cv2.imread(image_path)
    if img_origin is None:
        print(f"âŒ å›¾ç‰‡è¯»å–å¤±è´¥: {image_path}")
        return
    
    # è·å–åŸå›¾å°ºå¯¸ (é«˜åº¦, å®½åº¦)
    h_origin, w_origin = img_origin.shape[:2]
    
    # 3. åˆ¶ä½œæ¨¡å‹è¾“å…¥ (å¿…é¡»ç¼©æ”¾åˆ° 224x224)
    img_resized = cv2.resize(img_origin, (224, 224))
    rgb_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
    rgb_resized_float = np.float32(rgb_resized) / 255
    input_tensor = preprocess_image(rgb_resized_float, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    
    # 4. æ¨ç†
    wrapped_model = ModelWrapper(model)
    input_tensor = input_tensor.to(next(model.parameters()).device)
    
    with torch.no_grad():
        logits = wrapped_model(input_tensor)
        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]
    
    target_category = np.argmax(probs)
    print(f"ğŸ” é¢„æµ‹ç±»åˆ«ID: {target_category} (ç½®ä¿¡åº¦: {probs[target_category]:.2%})")

    # 5. ç”Ÿæˆ Grad-CAM Mask
    target_layers = get_target_layer(model, target_layer_name)
    with GradCAM(model=wrapped_model, target_layers=target_layers) as cam:
        targets = [ClassifierOutputTarget(target_category)]
        # è¿™é‡Œç”Ÿæˆçš„ grayscale_cam ä¹Ÿæ˜¯ 224x224 çš„
        grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]
        
        # === å…³é”®æ­¥éª¤ï¼šæŠŠ 224x224 çš„ mask æ‹‰ä¼¸å›åŸå›¾å°ºå¯¸ ===
        grayscale_cam_highres = cv2.resize(grayscale_cam, (w_origin, h_origin))
        
        # å‡†å¤‡åŸå›¾æ•°æ®ç”¨äºå åŠ 
        rgb_origin = cv2.cvtColor(img_origin, cv2.COLOR_BGR2RGB)
        rgb_origin_float = np.float32(rgb_origin) / 255
        
        # åœ¨åŸå›¾å°ºå¯¸ä¸Šå åŠ çƒ­åŠ›å›¾
        visualization_rgb = show_cam_on_image(rgb_origin_float, grayscale_cam_highres, use_rgb=True)

    # 6. ä¿å­˜
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
        
    full_save_path = os.path.join(save_dir, save_name)
    visualization_bgr = cv2.cvtColor(visualization_rgb, cv2.COLOR_RGB2BGR)
    
    cv2.imwrite(full_save_path, visualization_bgr)
    print(f"âœ… åŸå°ºå¯¸çƒ­åŠ›å›¾å·²ä¿å­˜: {full_save_path} ({w_origin}x{h_origin})")

if __name__ == '__main__':
    main()