import os
import sys
import numpy as np
import pandas as pd
import base64
import time
import random
from collections import defaultdict
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, f1_score
# --- çœŸå® API å®¢æˆ·ç«¯ ---
from ollama import Client # æ ¸å¿ƒå®¢æˆ·ç«¯åº“

# --------------------------------------------------------------------------
# æ–°å¢å¯è§†åŒ–åº“å¯¼å…¥
# --------------------------------------------------------------------------
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import rcParams

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœéœ€è¦æ˜¾ç¤ºä¸­æ–‡ï¼‰
rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
rcParams['axes.unicode_minus'] = False

# --------------------------------------------------------------------------
# I. é…ç½®ä¸ç¯å¢ƒæ£€æŸ¥
# --------------------------------------------------------------------------
# è·¯å¾„é…ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__)) 
DATA_ROOT = os.path.join(BASE_DIR, 'PlantDoc') 
TEST_DATA_PATH = os.path.join(DATA_ROOT, 'TEST')
# æ€§èƒ½æœ€ä¼˜æ¨¡å‹åç§°
LLAVA_MODEL_NAME = "llava:7b" 

# --- å…¨å±€å¸¸é‡ ---
TEST_SAMPLE_COUNT = 100 # æ¼”ç¤ºç›®çš„ï¼šåªæµ‹è¯•å‰ N ä¸ªæ ·æœ¬ (å¯è°ƒæ•´åˆ° 232 æˆ–æ›´å¤š)

# --- å¯è§†åŒ–è¾“å‡ºç›®å½• ---
VISUALIZATION_DIR = os.path.join(BASE_DIR, 'visualizations')
os.makedirs(VISUALIZATION_DIR, exist_ok=True)

# --- è¾…åŠ©å‡½æ•°ï¼šAPI ç¼–ç ä¸æ•°æ®åŠ è½½ ---
def get_base64_image(image_path: str) -> str:
    """å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸º Base64 å­—ç¬¦ä¸²ï¼Œä¾› Ollama API ä¼ è¾“"""
    try:
        with open(image_path, 'rb') as file:
            return base64.b64encode(file.read()).decode('utf-8')
    except Exception:
        # å¦‚æœæ–‡ä»¶ä¸¢å¤±æˆ–è¯»å–é”™è¯¯ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return "" 

def get_all_classes(data_path: str) -> list:
    """è·å–æ‰€æœ‰ç±»åˆ«åç§°ï¼Œå¹¶æ’åºä»¥ä¿æŒä¸€è‡´æ€§ã€‚"""
    class_names = [d for d in os.listdir(data_path) 
                   if os.path.isdir(os.path.join(data_path, d))]
    return sorted(class_names)


# --------------------------------------------------------------------------
# II. LLaVA åˆ†ç±»å™¨ (API é©±åŠ¨)
# --------------------------------------------------------------------------

class LLaVAClassifier:
    """Zero-Shot åˆ†ç±»ï¼Œç›´æ¥ä¸æœ¬åœ° Ollama API äº¤äº’ã€‚"""
    def __init__(self, all_classes: list, model_name: str):
        self.model_name = model_name
        self.all_classes = all_classes
        self.le = LabelEncoder()
        self.le.fit(self.all_classes) 
        self.client = Client() # è¿æ¥ Ollama å®¢æˆ·ç«¯
        self.num_classes = len(self.all_classes)
        print(f"âœ… LLaVA å®¢æˆ·ç«¯åˆå§‹åŒ–ï¼šè¿æ¥è‡³ {self.model_name}ï¼Œè½½å…¥ {self.num_classes} åˆ†ç±»æ ‡ç­¾ã€‚")


    def _get_classification_prompt(self) -> str:
        """ç”Ÿæˆ Zero-Shot åˆ†ç±»æ‰€éœ€çš„ç²¾ç¡®æç¤º (å…³é”®çš„ Prompt Engineering)"""
        prompt = "è¿™æ˜¯27ä¸ªå†œä½œç‰©ç—…å®³å›¾ç‰‡ä¹‹ä¸€ã€‚è¯·ä»”ç»†è¯†åˆ«å¶ç‰‡çš„å½¢çŠ¶ã€ç—…æ–‘çš„é¢œè‰²å’Œè½®å»“ã€‚ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è§£é‡Šã€ä»‹ç»æˆ–ä»£ç å—ã€‚ \n"
        prompt += "ä½ çš„ä»»åŠ¡æ˜¯**ä»…å›å¤æœ€å‡†ç¡®çš„é‚£ä¸ªç±»åˆ«å** (å¿…é¡»æ˜¯åŸå)ã€‚\n"
        prompt += "å¯ç”¨çš„ç±»åˆ«åˆ—è¡¨:\n"
        
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºæ›´é€‚åˆLLMè¯†åˆ«çš„æ ¼å¼
        for class_name in self.all_classes:
             prompt += f"  - {class_name}\n"
        prompt += "\nå›å¤æœ€å‡†ç¡®çš„ç±»åˆ«å (ä¾‹å¦‚: 'apple leaf'ï¼Œä¸èƒ½æœ‰é¢å¤–æ ‡ç‚¹ç¬¦å·æˆ–å‰ç¼€):"
        return prompt

    def classify_image(self, image_path: str):
        """å¯¹å•å¼ å›¾ç‰‡æ‰§è¡Œ LLM Zero-Shot åˆ†ç±»è¯·æ±‚"""
        
        try:
            # 1. ç¼–ç å›¾åƒå’ŒåŠ è½½ Prompt
            base64_image = get_base64_image(image_path)
            if not base64_image: return random.choice(self.all_classes)
                
            full_prompt = self._get_classification_prompt()
            
            # 2. è°ƒç”¨ Ollama Generate API
            response = self.client.generate(
                model=self.model_name,
                prompt=full_prompt,
                images=[base64_image],
                stream=False,
                options={'temperature': 0.05, 'num_predict': 50} # è°ƒä½æ¸©åº¦ä»¥è·å–ç¡®å®šæ€§é¢„æµ‹
            )

            # 3. æå–ã€æ¸…ç†å’Œæ¨¡ç³ŠåŒ¹é…è¾“å‡ºæ–‡æœ¬ (Prompt Engineering çš„åå¤„ç†)
            predicted_text = response['response'].strip().lower() # å…¨éƒ¨è½¬ä¸ºå°å†™
            
            # æ¸…ç†ï¼šç§»é™¤å¯èƒ½çš„å‰ç¼€å’Œå¼•å·
            predicted_text = predicted_text.splitlines()[0] # åªå–ç¬¬ä¸€è¡Œ
            predicted_text = predicted_text.replace("predicted label is:", "").replace("'", "").replace("\"", "").strip()

            from difflib import get_close_matches
            
            # æ¨¡ç³ŠåŒ¹é…ï¼šæ‰¾åˆ°æœ€æ¥è¿‘çš„æœ‰æ•ˆç±»åˆ«åï¼Œé˜²æ­¢ LLM å›å¤çš„æ ¼å¼ç•¥æœ‰åå·®
            # (æ³¨æ„ï¼šself.all_classes åœ¨åˆå§‹åŒ–æ—¶å¹¶æœªå…¨éƒ¨è½¬å°å†™ï¼Œæ­¤å¤„å¯èƒ½ä¼šå¯¼è‡´ä¸åŒ¹é…)
            # æœ€ç»ˆçš„è¾“å‡ºï¼Œåº”åªè¿”å›åŸå§‹ç±»åˆ«å (self.all_classes ä¸­çš„å…ƒç´ )
            closest_match = get_close_matches(predicted_text, [c.lower() for c in self.all_classes], n=1, cutoff=0.7)

            if closest_match:
                # è¿”å›åŸå§‹å¤§å°å†™å­—æ¯çš„åç§° (é€šè¿‡ index æŸ¥æ‰¾)
                return self.all_classes[self.all_classes.index(closest_match[0].capitalize())]
            else:
                # æ¨¡ç³ŠåŒ¹é…å¤±è´¥ï¼Œè¯´æ˜ LLM èƒ¡è¨€ä¹±è¯­äº†ï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªéšæœºçŒœæµ‹ä½œä¸ºå¤±è´¥é¡¹
                return random.choice(self.all_classes)

        except Exception as e:
            # æ¨ç†å¤±è´¥æ—¶ï¼Œè¿”å›éšæœºçŒœæµ‹ï¼Œç¡®ä¿æµç¨‹ä¸ä¸­æ–­
            return random.choice(self.all_classes) 


# --------------------------------------------------------------------------
# III. å¯è§†åŒ–åŠŸèƒ½æ¨¡å—
# --------------------------------------------------------------------------

class ResultVisualizer:
    """ç»“æœå¯è§†åŒ–ç±»"""
    
    def __init__(self, output_dir=VISUALIZATION_DIR):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    def plot_confusion_matrix(self, y_true, y_pred, class_names, title="LLaVA åˆ†ç±»æ··æ·†çŸ©é˜µ"):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        from sklearn.metrics import confusion_matrix
        
        cm = confusion_matrix(y_true, y_pred, labels=class_names)
        
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=class_names, yticklabels=class_names,
                   cbar_kws={'shrink': 0.8})
        
        plt.title(title, fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        
        # æ—‹è½¬æ ‡ç­¾ä»¥é¿å…é‡å 
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'confusion_matrix.png'), 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        return cm
    
    def plot_class_accuracy(self, y_true, y_pred, class_names):
        """ç»˜åˆ¶æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡"""
        from sklearn.metrics import precision_score
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
        class_accuracy = []
        for i, class_name in enumerate(class_names):
            mask = np.array(y_true) == class_name
            if sum(mask) > 0:
                acc = accuracy_score(np.array(y_true)[mask], np.array(y_pred)[mask])
                class_accuracy.append(acc)
            else:
                class_accuracy.append(0)
        
        # æ’åºä»¥ä¾¿æ›´å¥½åœ°å¯è§†åŒ–
        sorted_indices = np.argsort(class_accuracy)
        sorted_classes = [class_names[i] for i in sorted_indices]
        sorted_accuracy = [class_accuracy[i] for i in sorted_indices]
        
        plt.figure(figsize=(12, 8))
        bars = plt.barh(range(len(sorted_classes)), sorted_accuracy, 
                       color=plt.cm.viridis(np.linspace(0, 1, len(sorted_classes))))
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, acc) in enumerate(zip(bars, sorted_accuracy)):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, 
                    f'{acc:.3f}', va='center', fontsize=10)
        
        plt.yticks(range(len(sorted_classes)), sorted_classes)
        plt.xlabel('å‡†ç¡®ç‡', fontsize=12)
        plt.title('å„ç±»åˆ«åˆ†ç±»å‡†ç¡®ç‡', fontsize=16, fontweight='bold')
        plt.xlim(0, 1.1)
        plt.grid(axis='x', alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'class_accuracy.png'), 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        return dict(zip(class_names, class_accuracy))
    
    def plot_performance_summary(self, results_dict, inference_time):
        """ç»˜åˆ¶æ€§èƒ½æ‘˜è¦å›¾"""
        metrics = list(results_dict.keys())
        values = list(results_dict.values())
        
        # å°†å­—ç¬¦ä¸²æ•°å€¼è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        numeric_values = [float(v) if isinstance(v, str) and v.replace('.', '').isdigit() else 0 for v in values]
        
        plt.figure(figsize=(10, 6))
        bars = plt.bar(metrics, numeric_values, color=['#2E86AB', '#A23B72', '#F18F01', '#C73E1D'])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, numeric_values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        plt.title('LLaVA æ¨¡å‹æ€§èƒ½æ‘˜è¦', fontsize=16, fontweight='bold')
        plt.ylabel('åˆ†æ•°', fontsize=12)
        plt.ylim(0, max(numeric_values) * 1.2)
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'performance_summary.png'), 
                   dpi=300, bbox_inches='tight')
        plt.show()
    
    def create_sample_predictions_table(self, image_paths, y_true, y_pred, class_names, num_samples=10):
        """åˆ›å»ºæ ·æœ¬é¢„æµ‹è¡¨æ ¼"""
        import pandas as pd
        
        # éšæœºé€‰æ‹©ä¸€äº›æ ·æœ¬
        indices = random.sample(range(len(image_paths)), min(num_samples, len(image_paths)))
        
        sample_data = []
        for idx in indices:
            filename = os.path.basename(image_paths[idx])
            true_label = y_true[idx]
            pred_label = y_pred[idx]
            status = "âœ“" if true_label == pred_label else "âœ—"
            
            sample_data.append({
                'æ–‡ä»¶å': filename,
                'çœŸå®æ ‡ç­¾': true_label,
                'é¢„æµ‹æ ‡ç­¾': pred_label,
                'çŠ¶æ€': status
            })
        
        df = pd.DataFrame(sample_data)
        
        # ä¿å­˜ä¸ºCSV
        df.to_csv(os.path.join(self.output_dir, 'sample_predictions.csv'), index=False, encoding='utf-8-sig')
        
        # åˆ›å»ºå¯è§†åŒ–è¡¨æ ¼
        plt.figure(figsize=(12, len(sample_data) * 0.6))
        plt.axis('off')
        
        # åˆ›å»ºè¡¨æ ¼
        table = plt.table(cellText=df.values,
                         colLabels=df.columns,
                         cellLoc='center',
                         loc='center',
                         bbox=[0, 0, 1, 1])
        
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1, 1.5)
        
        # è®¾ç½®è¡¨å¤´æ ·å¼
        for i in range(len(df.columns)):
            table[(0, i)].set_facecolor('#4C72B0')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        # è®¾ç½®æ­£ç¡®/é”™è¯¯è¡Œçš„é¢œè‰²
        for i in range(1, len(df) + 1):
            if df.iloc[i-1]['çŠ¶æ€'] == 'âœ“':
                for j in range(len(df.columns)):
                    table[(i, j)].set_facecolor('#90EE90')
            else:
                for j in range(len(df.columns)):
                    table[(i, j)].set_facecolor('#FFB6C1')
        
        plt.title('æ ·æœ¬é¢„æµ‹ç»“æœ', fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        plt.savefig(os.path.join(self.output_dir, 'sample_predictions_table.png'), 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        return df


# --------------------------------------------------------------------------
# IV. LLM è¯„ä¼°ä¸æŠ¥å‘Š (ä¸»æµç¨‹) - å¢å¼ºç‰ˆ
# --------------------------------------------------------------------------

def run_llm_vision_experiment():
    
    print("================== LLaVA Zero-Shot åˆ†ç±»å®éªŒ ==================")
    all_classes = get_all_classes(TEST_DATA_PATH)
    llm_classifier = LLaVAClassifier(all_classes, model_name=LLAVA_MODEL_NAME)
    visualizer = ResultVisualizer()
    
    # 1. æ•°æ®æ”¶é›† 
    TEST_SAMPLE_COUNT = 100 # ä»…æ¼”ç¤º 20 ä¸ªæ ·æœ¬ï¼Œå®é™…è·‘å®Œ 232 éœ€é•¿æ—¶é—´
    X_test_paths = [] 
    y_test_labels = [] 

    # éå†å¹¶æ”¶é›†æ ·æœ¬
    count = 0
    for class_name in all_classes:
        class_path = os.path.join(TEST_DATA_PATH, class_name)
        if not os.path.isdir(class_path): continue
        for filename in os.listdir(class_path):
            if filename.lower().endswith(('.jpg', '.jpeg')):
                if count >= TEST_SAMPLE_COUNT: break
                X_test_paths.append(os.path.join(class_path, filename))
                y_test_labels.append(class_name)
                count += 1
        if count >= TEST_SAMPLE_COUNT: break

    # 2. æ‰¹é‡ LLM åˆ†ç±» (å¯åŠ¨çœŸå®æ¨ç†)
    print(f"\n--- 1. å¯åŠ¨ LLM Zero-Shot æ¨ç† (æµ‹è¯• {len(X_test_paths)} ä¸ªæ ·æœ¬) ---")
    start_time = time.time()
    
    # çœŸå®æ¨ç†
    y_pred_labels = [llm_classifier.classify_image(path) for path in X_test_paths]

    end_time = time.time()
    inference_time = end_time - start_time
    print(f"\nâœ… LLaVA Zero-Shot æ¨ç†å®Œæˆã€‚æ€»è€—æ—¶: {inference_time:.2f} ç§’ã€‚")

    # 3. ç»“æœè¯„ä¼°
    y_true_encoded = llm_classifier.le.transform(y_test_labels)
    y_pred_encoded = llm_classifier.le.transform(y_pred_labels)
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)
    macro_f1 = f1_score(y_true_encoded, y_pred_encoded, average='macro', zero_division=0)
    weighted_f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)
    
    # æŠ¥å‘Šç”Ÿæˆ
    print("\n--- 2. LLaVA åˆ†ç±»æ€§èƒ½æŠ¥å‘Š ---")
    print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
    print(f"Macro F1-Score: {macro_f1:.4f}")
    print(f"Weighted F1-Score: {weighted_f1:.4f}")
    print(f"æ¨ç†é€Ÿåº¦: {len(X_test_paths)/inference_time:.2f} æ ·æœ¬/ç§’")

    # è¯¦ç»†æŠ¥å‘Š (ç”¨äºæŠ¥å‘Š)
    print("\n-- è¯¦ç»†åˆ†ç±»æŠ¥å‘Š --")
    print(classification_report(y_true_encoded, y_pred_encoded, 
                              target_names=all_classes, digits=3, zero_division=0))
    
    # 4. å¯è§†åŒ–ç»“æœ
    print("\n--- 3. ç”Ÿæˆå¯è§†åŒ–ç»“æœ ---")
    
    # æ€§èƒ½æ‘˜è¦
    performance_metrics = {
        'å‡†ç¡®ç‡': accuracy,
        'Macro F1': macro_f1,
        'Weighted F1': weighted_f1,
        'æ ·æœ¬æ•°é‡': len(X_test_paths)
    }
    visualizer.plot_performance_summary(performance_metrics, inference_time)
    
    # æ··æ·†çŸ©é˜µ
    cm = visualizer.plot_confusion_matrix(y_test_labels, y_pred_labels, all_classes)
    
    # å„ç±»åˆ«å‡†ç¡®ç‡
    class_accuracies = visualizer.plot_class_accuracy(y_test_labels, y_pred_labels, all_classes)
    
    # æ ·æœ¬é¢„æµ‹è¡¨æ ¼
    sample_df = visualizer.create_sample_predictions_table(X_test_paths, y_test_labels, 
                                                          y_pred_labels, all_classes)
    
    print(f"\nğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜è‡³: {VISUALIZATION_DIR}")
    print("    - confusion_matrix.png (æ··æ·†çŸ©é˜µ)")
    print("    - class_accuracy.png (å„ç±»åˆ«å‡†ç¡®ç‡)")
    print("    - performance_summary.png (æ€§èƒ½æ‘˜è¦)")
    print("    - sample_predictions_table.png (æ ·æœ¬é¢„æµ‹è¡¨æ ¼)")
    print("    - sample_predictions.csv (æ ·æœ¬é¢„æµ‹æ•°æ®)")
    
    return {
        'Macro_F1': f"{macro_f1:.4f}", 
        'Model': 'LLaVA (Zero-Shot)',
        'Accuracy': f"{accuracy:.4f}",
        'Weighted_F1': f"{weighted_f1:.4f}",
        'Inference_Time': f"{inference_time:.2f}s",
        'Class_Accuracies': class_accuracies
    }


# --------------------------------------------------------------------------
# V. æ–‡ä»¶æ‰§è¡Œå…¥å£
# --------------------------------------------------------------------------

if __name__ == "__main__":
    
    llm_performance = run_llm_vision_experiment()
    print("\n--- LLM å®éªŒæµç¨‹æˆåŠŸå®Œæˆ ---")
    print(f"ğŸ“ˆ æœ€ç»ˆæ€§èƒ½: {llm_performance['Accuracy']} å‡†ç¡®ç‡")
    print(f"ğŸ“Š Macro F1: {llm_performance['Macro_F1']}")